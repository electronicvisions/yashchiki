@Library("jenlib") _

Closure cleanupSteps = {
	// NOTE: sudo commands have been manually permitted
	// remove sandboxes
	sh "sudo /bin/rm -rf \"${WORKSPACE}/sandboxes/\" || exit 0"
	// remove tmp spack
	sh "sudo /bin/rm -rf \"/tmp/${NODE_NAME}/\""
	// the spack repository gets bind mounted into the sandbox and owned by
	// spack user during build -> revert prior to cleaning worksapce
	sh "[ -d \"$WORKSPACE/spack\" ] && sudo chown -R vis_jenkins \"$WORKSPACE/spack\" || true"
	cleanWs(patterns: [[pattern: 'download_cache/', type: 'EXCLUDE']],
	        deleteDirs: true)
}

pipeline {
	agent { label 'conviz1||conviz2' }

	options {
		timestamps()
		skipDefaultCheckout()
	}

	parameters {
		string(name: 'BUILD_CACHE_NAME',
			   defaultValue: 'init_from_2023-10-24',
			   description: 'Which buildcache to use? They reside under $HOME/build_caches/$BUILD_CACHE_NAME and will be created if they do not exist.')
	}

	stages {
		stage('Container Build') {
			// TODO: remove once unused
			environment {
				CONTAINER_STYLE = "visionary"
				YASHCHIKI_INSTALL = "${WORKSPACE}/yashchiki"
				YASHCHIKI_META_DIR = "${WORKSPACE}/meta"
				YASHCHIKI_CACHES_ROOT = "${HOME}"
				YASHCHIKI_SPACK_PATH = "${env.WORKSPACE}/spack"
				YASHCHIKI_SANDBOXES = "sandboxes"
				YASHCHIKI_PROXY_HTTP = "http://proxy.kip.uni-heidelberg.de:8080"
				YASHCHIKI_PROXY_HTTPS = "http://proxy.kip.uni-heidelberg.de:8080"
				YASHCHIKI_BUILD_CACHE_ON_FAILURE_NAME = get_build_cache_on_failure_name()
				BUILD_CACHE_NAME = "${params.BUILD_CACHE_NAME}"  // propagate parameter to environment
			}
			stages {
				stage('Pre-build Cleanup') {
					steps {
						script {
							cleanupSteps()
						}
					}
				}
				stage('yashchiki Checkout') {
					steps {
						script {
							sh "git clone ssh://hudson@brainscales-r.kip.uni-heidelberg.de:29418/waf.git symwaf2ic"
							sh "cd symwaf2ic && singularity exec /containers/stable/latest make"
							if (!env.GERRIT_CHANGE_NUMBER) {
								sh "singularity exec /containers/stable/latest ./symwaf2ic/waf setup --project=yashchiki --clone-depth=2"
							} else {
								sh "singularity exec /containers/stable/latest ./symwaf2ic/waf setup --project=yashchiki --clone-depth=2 --gerrit-changes=${GERRIT_CHANGE_NUMBER} --gerrit-url=ssh://hudson@${GERRIT_HOST}:${GERRIT_PORT}"
							}
							sh "singularity exec /containers/stable/latest ./symwaf2ic/waf configure install"
						}
					}
				}
				stage('Dump Meta Info') {
					steps {
						sh "mkdir -p ${YASHCHIKI_META_DIR}"
						sh "bash bin/yashchiki_dump_meta_info.sh"
						script {
							if (isTriggeredByGerrit()) {
								sh "bash bin/yashchiki_notify_gerrit.sh -m 'Build containing this change started..'"
							}
						}
					}
				}
				stage('Deploy utilities') {
					steps {
						sh "bash bin/yashchiki_deploy_utilities.sh"
					}
				}
				stage('Build container image') {
					steps {
						script {
							try {
								// extract options from gerrit comment
								boolean with_debug = false
								boolean with_spack_verbose = false
								if (isTriggeredByGerrit()) {
									gerrit_comment = jesh(script: "echo '${GERRIT_EVENT_COMMENT_TEXT}' | base64 -d", returnStdout: true)
									with_debug = gerrit_comment.contains("WITH_DEBUG")
									with_spack_verbose = gerrit_comment.contains("WITH_SPACK_VERBOSE")
									env.BUILD_CACHE_NAME = jesh(script: "bash bin/yashchiki_get_build_cache_name.sh", returnStdout: true)
								}

								sh "python3 bin/yashchiki visionary ${WORKSPACE}/spack singularity_visionary_temp.img " +
								   "--log-dir=log " +
								   "--proxy-http=${YASHCHIKI_PROXY_HTTP} " +
								   "--proxy-https=${YASHCHIKI_PROXY_HTTPS} " +
								   "--tmp-subdir=${env.NODE_NAME} " +
								   "--meta-dir=${YASHCHIKI_META_DIR} " +
								   "--caches-dir=${YASHCHIKI_CACHES_ROOT} " +
								   "--sandboxes-dir=${YASHCHIKI_SANDBOXES} " +
								   "--host-env-filename=${WORKSPACE}/host.env " +
								   "--build-cache-name=${BUILD_CACHE_NAME} " +
								   ("${CONTAINER_BUILD_TYPE}" == "stable" ? "--update-build-cache " : "") +
								   "--recipe-filename=${WORKSPACE}/visionary_recipe.def " +
								   "--build-cache-on-failure-name=${YASHCHIKI_BUILD_CACHE_ON_FAILURE_NAME} " +
								   (with_debug ? "--debug " : "") +
								   (with_spack_verbose ? "--spack-verbose " : "")
							} catch (Throwable t) {
								archiveArtifacts "errors_concretization.log"
								throw t
							}
							archiveArtifacts(artifacts: "sandboxes/*/opt/spack_specs/*.yaml", allowEmptyArchive: true)
							archiveArtifacts(artifacts: "log/*.log", allowEmptyArchive: true)
						}
					}
				}
				stage('Export container') {
					steps {
						script {
							// we only want the container name, tail everything else
							CONTAINER_IMAGE = sh(script: "bash bin/yashchiki_deploy_container.sh | tail -n 1", returnStdout: true).trim()
							if (isTriggeredByGerrit()) {
								sh "bash bin/yashchiki_notify_gerrit.sh -t Build -c \"$CONTAINER_IMAGE\""
							}
						}
					}
				}
			}
			post {
				failure {
					script {
						cache_failed = sh(script: "bash bin/yashchiki_create_temporary_build_cache_after_failure.sh", returnStdout: true).trim()
						if (isTriggeredByGerrit()) {
							sh "bash bin/yashchiki_notify_gerrit.sh -v -1 -t Build -m \"Successfully built packages stored in cache. Resume by issuing:\nWITH_CACHE_NAME=${cache_failed}\n\nIn your next gerrit comment, NOT commit message!\""
						}
					}
				}
				cleanup {
					archiveArtifacts "host.env"
					archiveArtifacts "out_singularity_build_visionary_recipe.txt"
				}
			}
		}

		// Container verification stage: Build visionary metaprojects
		stage('Container Verification') {
			parallel {

				// BSS1
				stage('NMPM Software') {
					steps {
						build(job: 'bld_gerrit-meta-nmpm-software',
						      parameters: [string(name: 'OVERWRITE_DEFAULT_CONTAINER_IMAGE', value: CONTAINER_IMAGE)])
					}
				}

				// BSS2
				stage('PPU Toolchain') {
					steps {
						build(job: 'bld_gerrit-ppu-toolchain-dependencies',
						      parameters: [string(name: 'OVERWRITE_DEFAULT_CONTAINER_IMAGE', value: CONTAINER_IMAGE)])
					}
				}
				stage('haldls') {
					steps {
						build(job: 'bld_gerrit-haldls-dependencies',
						      parameters: [string(name: 'OVERWRITE_DEFAULT_CONTAINER_IMAGE', value: CONTAINER_IMAGE)])
					}
				}
				stage('hxtorch') {
					steps {
						build(job: 'bld_gerrit-hxtorch-dependencies',
						      parameters: [string(name: 'OVERWRITE_DEFAULT_CONTAINER_IMAGE', value: CONTAINER_IMAGE)])
					}
				}
				stage('pynn-brainscales') {
					steps {
						build(job: 'bld_gerrit-pynn-brainscales-dependencies',
						      parameters: [string(name: 'OVERWRITE_DEFAULT_CONTAINER_IMAGE', value: CONTAINER_IMAGE)])
					}
				}
				stage('documentation-brainscales2') {
					steps {
						build(job: 'doc_gerrit_documentation-brainscales2-dependencies',
						      parameters: [string(name: 'OVERWRITE_DEFAULT_CONTAINER_IMAGE', value: CONTAINER_IMAGE)])
					}
				}

				// Visionary KiCad library
				stage('pcb-kicad-lib') {
					steps {
						build(job: 'bld_gerrit_pcb-kicad-lib_dependencies',
							  parameters: [string(name: 'OVERWRITE_DEFAULT_CONTAINER_IMAGE', value: CONTAINER_IMAGE)])
					}
				}
				// Visionary lab tools
				stage('labcontrol') {
					steps {
						build(job: 'bld_gerrit_labcontrol_dependencies',
							  parameters: [string(name: 'OVERWRITE_DEFAULT_CONTAINER_IMAGE', value: CONTAINER_IMAGE)])
					}
				}
			}
			post {
				success {
					script {
						if (isTriggeredByGerrit()) {
							jesh "bash bin/yashchiki_notify_gerrit.sh -v 1 -t Tests -c '${CONTAINER_IMAGE}'"
						}
					}
				}
				unstable {
					script {
						if (isTriggeredByGerrit()) {
							jesh "bash bin/yashchiki_notify_gerrit.sh -v 0 -t Tests -c '${CONTAINER_IMAGE}'"
						}
					}
				}
				failure {
					script {
						if (isTriggeredByGerrit()) {
							jesh "bash bin/yashchiki_notify_gerrit.sh -v -1 -t Tests -c '${CONTAINER_IMAGE}'"
						}
					}
				}
			}
		}
	}
	post {
		failure {
			notifyFailure(mattermostChannel: "#spack")
		}
		cleanup {
			// Clean build artifacts because otherwise the latest build from each jenkins job can take up to 50GB.
			// 2 executors and 5 Jenkins-Jobs (testing, testing-spack, testing-asic, stable, stable-asic) will slowly but surely eat away memory.
			script {
				cleanupSteps()
			}
		}
	}
}

String get_build_cache_on_failure_name() {
	return (CONTAINER_BUILD_TYPE == "testing" ? "c${GERRIT_CHANGE_NUMBER}p${GERRIT_PATCHSET_NUMBER}" : jesh("echo 'stable_\$(date --iso)'", returnStdout: true))
}
